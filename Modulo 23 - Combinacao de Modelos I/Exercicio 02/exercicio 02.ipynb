{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a233c5c4",
   "metadata": {},
   "source": [
    "## Exercício 2 - Módulo 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17aca74",
   "metadata": {},
   "source": [
    "#### 1) Monte um passo a passo para o algoritimo RF:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356cc5c",
   "metadata": {},
   "source": [
    "1- A partir de um dataset, realizar uma amostragem com reposição (BootStrap) nas linhas, e fazer uma seleção aleatória nas colunas(Feature Selection) de forma a montar um número desejado de conjuntos reamostrados.\n",
    "2- O número de amostras vai ser determinado por uma regra, se for de Classificação: $$m=\\sqrt{p}$$.\n",
    "3- Se for Regressão: $$m=\\frac{p}{3}$$\n",
    "4- Aplicar o Random Forest para construir árvores de decisão em cada conjunto diferente criado.\n",
    "5- Com o resultado de cada modelo, determinar o resultado final.\n",
    "6- Se o resultado for binário, fazer uma contagem de qual mais apareceu, caso seja numérico, faz-se uma média com a soma dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fbae4",
   "metadata": {},
   "source": [
    "#### 2) Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9df17a",
   "metadata": {},
   "source": [
    "É um método criado por Leo Breiman a fim de reduzir ainda mais a variância do Bagging, e evitar o overfitting nos modelos de árvore de decisão. A partir de um conjunto de dados, os dados são reamostrados (com reposição) em vários conjuntos, e as variáveis também são reamostradas em números menores, criando conjuntos de dados que podem ser completamente diferentes. Uma árvore de decisão é modelada a partir de cada novo conjunto individual, e o resultado final é agregado utilizando todos os modelos gerados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc99096",
   "metadata": {},
   "source": [
    "#### 3) Qual a diferença entre Bagging e Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b1de7",
   "metadata": {},
   "source": [
    "O Random Forest é uma variação mais complexa do Bagging, onde além de reamostragem das linhas, as colunas também são reamostradas, criando mais diversidade entre os conjuntos de dados gerados. No Bagging todas as colunas são mantidas como no original, enquanto no Random Forest uma porção menor das colunas são selecionadas em cada reamostragem. No Random Forest os modelos ajustados são sempre árvores de decisão, enquanto no Bagging outros modelos podem ser usados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371887f9",
   "metadata": {},
   "source": [
    "#### 4) Implementar em python o Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "920baccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10779.22475269 10797.42056002  5934.77879593 ...  7457.65597709\n",
      "  7506.61655594  6098.95941359]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "df = pd.read_csv(\"credit_scoring.csv\")\n",
    "df2 = df.drop(['mau','data_ref','id_cliente','sexo','tipo_renda','educacao','estado_civil','tipo_residencia'], axis=1)\n",
    "\n",
    "#Removi todas variáveis categóricas pra simplificar\n",
    "\n",
    "y = df2['renda']\n",
    "X = df2.drop('renda', axis=1)\n",
    "\n",
    "# Parâmetros do Random Forest\n",
    "\n",
    "n_trees = 100  # Número de árvores\n",
    "max_depth = 5  # Profundidade máxima das árvores\n",
    "bootstrap_size = len(X)  # Tamanho do conjunto de bootstrap (amostragem com reposição)\n",
    "\n",
    "\n",
    "# Construindo o Random Forest\n",
    "forest = []\n",
    "for n in range(n_trees):\n",
    "    # Amostragem com reposição para criar o conjunto de bootstrap\n",
    "    bootstrap_indices = np.random.choice(bootstrap_size, bootstrap_size, replace=True)\n",
    "    X_bootstrap = X.iloc[bootstrap_indices]\n",
    "    y_bootstrap = y.iloc[bootstrap_indices]\n",
    "\n",
    "    # Construir árvore de decisão\n",
    "    tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    tree.fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "    # Adicionar árvore ao Random Forest\n",
    "    forest.append(tree)\n",
    "\n",
    "# Fazendo as previsões com o Random Forest\n",
    "predictions = []\n",
    "for tree in forest:\n",
    "    predictions.append(tree.predict(X))\n",
    "\n",
    "\n",
    "#Calculando a média das previsões\n",
    "mean_predictions = np.mean(predictions) \n",
    "\n",
    "# Média das previsões para cada linha\n",
    "final_predictions = np.mean(predictions, axis=0)\n",
    "print(final_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
